{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "206c0e97",
   "metadata": {},
   "source": [
    "\n",
    "###  List of Table to pull in API and be loaded in Bronze layer:\n",
    "- Address\n",
    "- Customer\n",
    "- Person\n",
    "- Product\n",
    "- ProductCategory\n",
    "- ProductDescription\n",
    "- ProductModel\n",
    "- SalesOrderdetail\n",
    "- SalesOrderHeader\n",
    "- Store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b23d8d",
   "metadata": {},
   "source": [
    "Scripts for pulling data from public AdventureWorks API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6cba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import schema_of_json, from_json, col, lit\n",
    "\n",
    "def fetch_api_data(endpoint: str):\n",
    "    \"\"\"\n",
    "    Fetches data from a given public API endpoint and returns a Spark DataFrame with inferred schema.\n",
    "    \n",
    "    Args:\n",
    "        endpoint (str): The API endpoint (e.g., 'addresses', 'customers', etc.)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: Spark DataFrame containing the API response data with inferred schema\n",
    "    \"\"\"\n",
    "    base_url = \"https://demodata.grapecity.com/adventureworks/api/v1/\"\n",
    "    url = f\"{base_url}{endpoint}\"\n",
    "    headers = {\n",
    "        \"Accept\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Extract column order from first record\n",
    "    column_order = list(data[0].keys())\n",
    "\n",
    "    # Initialize SparkSession\n",
    "    spark = SparkSession.builder.appName(\"APIData\").getOrCreate()\n",
    "\n",
    "    # Convert JSON objects to strings\n",
    "    json_strings = [json.dumps(record) for record in data]\n",
    "    df_raw = spark.createDataFrame(json_strings, \"string\").toDF(\"raw_json\")\n",
    "\n",
    "    # Infer schema from a sample\n",
    "    sample_json = df_raw.select(\"raw_json\").head()[0]\n",
    "    inferred_schema = spark.range(1).select(schema_of_json(lit(sample_json))).collect()[0][0]\n",
    "\n",
    "    # Parse JSON strings into structured DataFrame\n",
    "    df_parsed = df_raw.withColumn(\"parsed\", from_json(\"raw_json\", inferred_schema))\n",
    "    df_structured = df_parsed.select(\"parsed.*\")\n",
    "\n",
    "    # Reorder columns to match original API order\n",
    "    df = df_structured.select([col(c) for c in column_order if c in df_structured.columns])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc94377",
   "metadata": {},
   "source": [
    "Assigning values to the variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5557ec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [\n",
    "    \"addresses\", \"customers\", \"persons\", \"products\", \"productCategories\", \"productDescriptions\",\n",
    "    \"productModels\", \"salesOrderDetails\", \"salesOrders\", \"stores\" \n",
    "]\n",
    "\n",
    "# tables = [\n",
    "#     \"persons\"\n",
    "# ]\n",
    "\n",
    "schema = \"bronze_adworks_rich\"  # Bronze schema name\n",
    "catalog = \"adventureworks_dev\"  # Unity Catalog name\n",
    "\n",
    "# for table in tables:\n",
    "#     df = fetch_api_data(table)\n",
    "#     display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bfb45f",
   "metadata": {},
   "source": [
    "Scripts for checking\n",
    "if it has nested JSON, then create new columns; if it has not, then create it as is:\n",
    "\n",
    "Then write the dataframe into the delta table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e516a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "%python\n",
    "from pyspark.sql.functions import col, current_timestamp\n",
    "\n",
    "for table in tables:\n",
    "    df = fetch_api_data(table)\n",
    "\n",
    "    if df.count() > 0:\n",
    "        if table in [\"stores\", \"persons\"]:\n",
    "            # Flatten the nested JSON data into new columns for tables with nested JSON\n",
    "            if table == \"stores\":\n",
    "                df = df.select(\n",
    "                    col(\"storeId\"),\n",
    "                    col(\"name\"),\n",
    "                    col(\"salesPersonId\"),\n",
    "                    col(\"demographics.AnnualSales\").alias(\"AnnualSales\"),\n",
    "                    col(\"demographics.AnnualRevenue\").alias(\"AnnualRevenue\"),\n",
    "                    col(\"demographics.BankName\").alias(\"BankName\"),\n",
    "                    col(\"demographics.BusinessType\").alias(\"BusinessType\"),\n",
    "                    col(\"demographics.YearOpened\").alias(\"YearOpened\"),\n",
    "                    col(\"demographics.Specialty\").alias(\"Specialty\"),\n",
    "                    col(\"demographics.SquareFeet\").alias(\"SquareFeet\"),\n",
    "                    col(\"demographics.Brands\").alias(\"Brands\"),\n",
    "                    col(\"demographics.Internet\").alias(\"Internet\"),\n",
    "                    col(\"demographics.NumberEmployees\").alias(\"NumberEmployees\"),\n",
    "                    col(\"modifiedDate\")\n",
    "                )\n",
    "            if table == \"persons\":\n",
    "                df = df.select(\n",
    "                    col(\"personId\"),\n",
    "                    col(\"personType\"),\n",
    "                    col(\"nameStyle\"),\n",
    "                    col(\"title\"),\n",
    "                    col(\"firstName\"),\n",
    "                    col(\"middleName\"),\n",
    "                    col(\"lastName\"),\n",
    "                    col(\"suffix\"),\n",
    "                    col(\"emailPromotion\"),\n",
    "                    col(\"additionalContactInfo\"),\n",
    "                    col(\"demographics.TotalPurchaseYTD\").alias(\"TotalPurchaseYTD\"),\n",
    "                    col(\"modifiedDate\")\n",
    "                )\n",
    "    \n",
    "        table_full_name = f\"{catalog}.{schema}.{table}\"\n",
    "    \n",
    "        # display(df)\n",
    "        df.write\\\n",
    "            .format(\"delta\")\\\n",
    "            .mode(\"append\")\\\n",
    "            .option(\"mergeSchema\", \"true\")\\\n",
    "            .saveAsTable(table_full_name)\n",
    "        print(f\"Saved '{table}' to Delta table: {table_full_name}\")\n",
    "    else:\n",
    "        print(f\"No data found for '{table}', skipping save.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
